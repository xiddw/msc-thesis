%!TEX root = ../Thesis.tex

\chapter{Experimentos y resultados}\label{ch:chap6}

\epigraphhead[70]{
\epigraph{``Data! Data! Data!'' he cried impatiently. 
``I can't make bricks without clay.''}{Sherlock Holmes}}

En los capítulos anteriores se ha descrito los diferentes algoritmos que se utilizarán para realizar la tarea de \sd, y que en esta sección se emplearán de acuerdo al marco experimental que se describe a continuación.

Inicialmente, las pruebas consistieron en usar los algoritmos presentados para selección de modelo usando datos que fueron generados aleatoriamente a partir de los parámetros de un \ac{HMM} inicial; para tener una idea general de su desempeño individual.

Para estas primeras pruebas, se simuló una cadena de Márkov oculta con base en parámetros fijos, generando tanto una secuencia de datos observados, como los supuestos datos o variables ocultas que forman la cadena de Márkov. Se utilizó muestreo ancestral para la simulación de estos datos.

Para un caso en específico, se tiene lo siguiente. Realizando la inferencia de parámetros del \ac{HMM}, se obtienen los siguientes resultados:

El primer algoritmo que se prueba, es el de selección de modelo usando un \ac{BIC}.

Como ya se comentó, se usará una variante de \ac{BIC} en donde se incorpora un término de regularización $\lambda$ para que correspondan en órdenes de magnitud tanto la log-verosimilitud del modelo encontrado como su penalización respectiva.

El problema inmediato que se presenta, es cómo realizar la selección del parámetro de regularización $\lambda$ que penalice de forma correcta la verosimilitud para los diferentes modelos propuestos. Si $\lambda$ es demasiado pequeño, entonces la penalización realmente no tendrá efecto y dado el sobre ajuste que se presenta al usar modelos más complejos, se preferirán siempre los modelos con más parámetros. Por otro lado, si al escoger $\lambda$ se da demasiado peso al término de regularización, entonces siempre se preferirán los modelos más sencillos.

Para encontrar el valor de $\lambda$ adecuado, se puede entonces formar una superficie con las diferentes curvas de selección \ac{BIC} de acuerdo a cómo varía $\lambda$, e inspeccionar esta superficie para encontrar una región de confianza en la que el valor de $\lambda$ es el adecuado.

Por otro lado, para la segunda prueba, se procedió a usar bootstrap con la estadística \ac{LLR} como ya se describió anteriormente en el \autoref{ch:chap3}, y haciendo la prueba de hipótesis del modelo de $n$ estados contra el de $n+1$ estados.

\section{Experimentos} % (fold)
\label{sec:experimentos}

Para los experimentos realizados, se generaron mediante un \ac{TTS} para la generación de las secuencias de prueba, lo que nos permitió tener un mayor control sobre el contenido como tal de las grabaciones, así como sobre los posibles ruidos o interferencias en la señal de audio.

Si bien, para probar el desempeño contra otras propuestas del estado del arte se suelen usar otro tipo de bases de datos (tales como \ac{NIST}, ...), éstas suelen no estar disponibles de forma libre, por lo que preferimos generar nosotros un conjunto de pruebas con el sintetizador de voz.

Usando dos motores para el sintetizador de voz, uno con voces en inglés y otro con voces en español, se generaron 6 secuencias de audio (3 en cada idioma) cuya duración así como el número de interlocutores que participan varía.

\subsection[Secuencia 1]{Secuencia 1: Edgar Allan Poe} % (fold)
\label{ssub:allanpoe}

  \input{Chapters/Chapter06_01} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\subsection[Secuencia 2]{Secuencia 2: Gabriel García Márquez} %(fold)
\label{ssub:soledad}

  \input{Chapters/Chapter06_02} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\subsection[Secuencia 3]{Secuencia 3: William Shakespeare}
\label{ssub:lear}

  \input{Chapters/Chapter06_03} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\subsection[Secuencia 4]{Secuencia 4: Manuel Acuña}
\label{ssub:nocturno}

  \input{Chapters/Chapter06_04} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\subsection[Secuencia 5]{Secuencia 5: Calderón de la Barca}
\label{ssub:calderon}

  \input{Chapters/Chapter06_05} 
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 

\subsection[Secuencia 6]{Secuencia 6: Andrew Lloyd Webber}
\label{ssub:cats}

  \input{Chapters/Chapter06_06}   


\section{Resultados}

A continuación se presentan la tabla \autoref{tab:carac} con las características de cada una de las secuencias utilizadas para las pruebas.

\begin{table}[bth]
  \centerline {
  \begin{tabularx}{1\textwidth}{X rrrccc} \toprule
    \tableheadline{Sec. Id.}& 
  	\tableheadline{Duración} & 
  	\tableheadline{$\#_{SAMPLES}$} &
  	\tableheadline{$\#_{WORDS}$} &  	
  	\tableheadline{$n_{TRUE}$} &
	  \\ \midrule
    ALLPOE~ & 12:06 min & 7218 & 140 & 6 \\ 
    GARMÁR~ &  6:55 min & 4154 &  90 & 4 \\
    WSHAKE~ &  2:43 min & 1636 & 160 & 4 \\ 
    MACUÑA~ & 10:41 min & 6414 & 120 & 3 \\ 
    CALDER~ &  1:07 min &  676 & 160 & 3 \\ 
    LLOYDW~ &  6.48 min & 4084 & 160 & 5 \\    
    \bottomrule
  \end{tabularx} 
  }
  \caption[Secuencias utilizadas en pruebas]{Descripción de características de secuencias utilizadas para las pruebas}  
  \label{tab:carac}
\end{table}

En la tabla \autoref{tab:resul} se muestran los resultados obtenidos de las pruebas realizadas. Para 5 de los 6 casos se acertó al modelo generador, siendo el caso presentado en la  \autoref{ssub:calderon} el único en el que no se logró inferir de forma correcta. Como se observa en su curva \ac{BIC} (\autoref{fig:seq5_bic3}), la mayoría de los modelos obtuvieron un puntaje similar, e incluso, el modelo con una mayor valoración fue otro ($n=5$). De ahí la importancia de realizar la segunda etapa de refinamiento para mediante pruebas de hiótesis discernir al modelo correcto. 

Como se muestra en la \autoref{fig:seq5_boot}, al momento de comparar el modelo verdadero ($n=3$) contra otro modelo ($n=4$), se rechaza la hipótesis nula de que el modelo generador sea el primero de estos, estando apenas el valor de $LLR_{obs}$ por debajo del valor de significancia usado; por lo que en caso de haber usado un umbral mucho más pequeño se habría logrado identificar de forma correcta al modelo verdadero.

\begin{table}[bth]
  \centerline {
  \begin{tabularx}{0.7\textwidth}{X rrrccc} \toprule
    \tableheadline{Sec. Id.}& 
  	\tableheadline{$n_{TRUE}$} &
  	\tableheadline{$n_{FOUND}$} & 
    \tableheadline{DER (\%)} 	
	  \\ \midrule
    ALLPOE~ & 6 & 6 & 03.324 \\ 
    GARMÁR~ & 4 & 4 & 00.652 \\
    WSHAKE~ & 4 & 4 & 12.353 \\ 
    MACUÑA~ & 3 & 3 & 00.343 \\ 
    CALDER~ & 4 & 3 & *08.092 \\ 
    LLOYDW~ & 5 & 5 & 01.170 \\    
    \bottomrule
  \end{tabularx} 
  }
  \caption[Resultados de pruebas realizadas]{Resultados de pruebas realizadas. Se observa en general que para la mayoría de las pruebas se encontró el modelo correcto, además de que se tiene un \ac{DER} en general abajo del 10\%. En el caso de la secuencia \texttt{CALDER}, se muestra el \ac{DER} correspondiente al modelo correcto.}  
  \label{tab:resul}
\end{table}

Por último, es importante resaltar también los tiempos de las pruebas que se realizaron, y que al ser técnicas computacionalmente demandantes, tardaron mucho en ejecutarse. Todas las pruebas se realizaron en una máquina de escritorio, con (...incluir especificaciones...). Para cada prueba se realizaron el mismo número de simulaciones, aunque en cada una varía la duración de cada grabación de audio, así como la longitud del diccionario de palabras utilizado. También es importante la complejidad de los modelos con los que se hicieron las pruebas de hipótesis, pues mientras más complejo un modelo, mayor número de parámetros se tienen que estimar a cada iteración del método.

En la tabla \autoref{tab:times} se muestra a detalle cuánto duró cada prueba.

\begin{table}[bth]
  \centerline {
  \begin{tabularx}{1.1\textwidth}{X rrrrr} \toprule
    \tableheadline{Sec. Id.}& 
  	\tableheadline{Duración} & 
  	\tableheadline{$\#_{WORDS}$} &  	
  	\tableheadline{Modelos} &  	
  	\tableheadline{Ejecución} &  	
	  \\ \midrule
    ALLPOE~ & 12:06 min & 140 & $~\lbrace 4, 5, 6, 7, 8 \rbrace~$ & $\sim 402$ hrs \\ 
    GARMÁR~ &  6:55 min &  90 & $~\lbrace 2, 3, 4, 5, 6 \rbrace~$ & $\sim 140$ hrs \\
    WSHAKE~ &  2:43 min & 160 & $~\lbrace 2, 3, 4, 5, 6 \rbrace~$ & $\sim  66$ hrs \\ 
    MACUÑA~ & 10:41 min & 120 & $~\lbrace 2, 3, 4, 5, 6 \rbrace~$ & $\sim 176$ hrs \\ 
    CALDER~ &  1:07 min & 160 & $~\lbrace 2, 3, 4, 5, 6 \rbrace~$ & $\sim  23$ hrs \\ 
    LLOYDW~ &  6.48 min & 160 & $~\lbrace 3, 4, 5, 6, 7 \rbrace~$ & $\sim 193$ hrs \\    
    \bottomrule
  \end{tabularx} 
  }
  \caption[Resultados de pruebas realizadas]{Resultados de pruebas realizadas. Se observa en general que para la mayoría de las pruebas se encontró el modelo correcto, además de que se tiene un \ac{DER} en general abajo del 10\%. En el caso de la secuencia \texttt{CALDER}, se muestra el \ac{DER} correspondiente al modelo correcto.}  
  \label{tab:resul}
\end{table}