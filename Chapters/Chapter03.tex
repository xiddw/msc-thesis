%!TEX root = ../Base.tex

%************************************************
\chapter{HMM usando EM} \label{ch:chap3}
%************************************************

Para resolver el modelo HMM, es decir, lograr estimar los parámetros que lo conforman, existen diferentes métodos y técnicas. En este trabajo de tesis se presentarán y platicará sobre dos de ellas. A saber, usando Expectation-Maximization, y usando simulaciones tipo Markov Chain MonteCarlo.

\section{Estimación de parámetros del HMM}

Si se tiene un conjunto de datos observados $\mb{X} = \lbrace x_1, ..., x_N \rbrace$, se pueden determinar los parámetros del HMM usando máxima verosimilitud. La función de verosimilitud se obtiene de la distribución conjunta \eqref{eqn:2-11} al marginalizar las variables latentes.
\begin{equation}
  p(\mb{X}, \theta) = \sum_Z p(\mb{X}, \mb{Z} \,|\, \theta)
\label{eqn:3-1}
\end{equation}

Sin embargo, la función obtenida presenta algunas dificultades, pues no se pueden con respecto a $n$, puesto que las variables latentes $z_n$ dependen  del estado anterior. Además, no es factible separar las sumas de estas $N$ variables, pues para cada una se tendría que considerar cada uno de sus $K$ posibles estados, y entonces el número de términos en la suma es del orden $K^N$, y crece exponencialmente con el largo de la cadena. Por esto y algunas otras razones, es que se descarta el estimar los parámetros del modelo por máxima verosimilitud.

Entonces, se buscará usar el algoritmo de \aem, en donde se hace una selección inicial de los parámetros que denotaremos como $\theta^{old}$. Luego, en el primer paso del \aem, conocido como \estep, se toman estos parámetros para encontrar la probabilidad a posteriori de las variables latetes $p(\mb{Z} \,|\, \mb{X}, \theta^{old})$ que se usará para evaluar la esperanza de el logaritmo de una función de verosimilitud completa, que es una función tanto de la primera estimación de $\theta^{old}$ así como de los nuevos parámetros $\theta$.

La función de verosimilitud completa se define entonces como sigue:
\begin{equation}
\mathcal{Q}(\theta, \theta^{old}) = 
  \sum_{\mb{Z}} p(\mb{Z} \,|\, \mb{X}, \theta^{old})
  ln p(\mb{X}, \mb{Z} \,|\, \theta).
\label{eqn:3-2}
\end{equation}

Se introduce además cierta notación para simplificar las expresiones que ahora se usarán. Se usará $\gamma(z_n)$ para denotar la distribución marginal posterior de la variable latente $z_n$, y $\xi(z_{n-1}, z_n)$ para denotar la distribución conjunta posterior de dos variables latentes sucesivas, es decir: 
\begin{gather}
\gamma(z_n) = p(z_n \,|\, \mb{X}, \theta^{old}) \label{eqn:3-3} \\
\xi(z_{n-1}, z_n) = p(z_{n-1}, z_n \,|\, \mb{X}, \theta^{old}) \label{eqn:3-4}
\end{gather}

Considerando entonces que $z_n$ es un vector binario, entonces se puede extender esta notación para cada uno de los componentes de la variable latente $z_n$, es decir, para denotar la probabilidad condicional $z_{nk} = 1$. Se
tomará entonces la esperanza de tanto $\gamma(z_{nk})$ como $\xi(z_{n-1, j}, z_{nk})$ y entonces
\begin{gather}
\gamma(z_{nk}) = \mathbb{E} \left[ z_{nk} \right] = \sum_Z  \gamma(\mb{z}) z_{nk} \label{eqn:3-5} \\
\xi(z_{n-1,j}, z_{nk}) = \mathbb{E} \left[z_{n-1, j} \cdot z_{nk} \right] = \sum_Z  \gamma(\mb{z}) z_{n-1, j} 
\cdot z_{nk}
\label{eqn:3-6}
\end{gather}

Si se sustituye $p(\mb{X}, \mb{Z} \,|\, \theta)$ de \eqref{eqn:2-11} en \eqref{eqn:3-2}, así como usando las definiciones \eqref{eqn:3-5} y \eqref{eqn:3-6}, y luego desarrollando el logaritmo, se obtiene: 

\begin{equation}
\begin{split}
\mathcal{Q}(\theta, \theta^{old}) = 
  \sum_{k=1}^K \gamma(z_{1k}) ln \pi_k + 
  \sum_{n=2}^N \sum_{j=1}^K \sum_{k=1}^K \xi(z_{n-1,j}, z_{nk}) ln A_{jk} + \\
  \sum_{n=1}^N \sum_{k=1}^K \gamma(z_{nk}) ln p(x_n \,|\, \phi_k)
\label{eqn:3-7}
\end{split}
\end{equation}

Por lo que entonces en el \estep~ se debe evaluar tanto $\gamma(z_{nk})$ como $\xi(z_{n-1,j}, z_{nk})$ de forma eficiente para luego continuar con la segunda etapa del algoritmo.

El segundo paso, también conocido como \mstep, consiste en maximizar la unción $\mathcal{Q}(\theta, \theta^{old})$ con respecto a cada uno de los parámetros $\theta = \lbrace \pi, \mb{A}, \phi \rbrace$ mientras que ahora $\gamma(z_{nk})$ y $\xi(z_{n-1,j}, z_{nk})$ se tratan como constantes.

Para maximizar entonces $\pi$, se deriva $\mathcal{Q}(\theta, \theta^{old})$ con respecto a $\pi_k$, usando multiplicadores de Lagrange para la restricción de $\sum_k \pi_k = 1$, por lo que entonces se tiene: 
\begin{equation*}
  \frac {\partial \mathcal{Q}(\theta, \theta^{old})}{\partial \pi_k} = 
  \frac {\partial}{\partial \pi_k} 
  \left[
    \sum_{k=1}^K \gamma(z_{1k}) ln \pi_k + \lambda (\sum_{k=1}^K \pi_k - 1) 
  \right]
\end{equation*}
y derivando y encontrando el valor de $\lambda$, para luego despejar $\pi_k$, se obtiene:
\begin{equation}
  \pi_k = \frac{\gamma(z_{1k})}{\sum_{j=1}^K \gamma(z_1j)}
\label{eqn:3-8}
\end{equation}
mientras que para maximizar $\mb{A}$, se deriva entonces $\mathcal{Q}(\theta, \theta^{old})$ con respecto a $A_{jk}$, considerando también las restricciones, es decir
\begin{equation*}
  \frac {\partial \mathcal{Q}(\theta, \theta^{old})}{\partial \pi_k} = 
  \frac {\partial}{\partial \pi_k} 
  \left[
    \sum_{n=2}^N \sum_{j=1}^K \sum_{k=1}^K \xi(z_{n-1,j}, z_{nk}) ln A_{jk} 
    + \lambda (\sum_{k=1}^K A_{jk} - 1) 
  \right]
\end{equation*}
y de la misma manera, resolviendo para $A_{jk}$ se obtiene
\begin{equation}
A_{jk} = \sum_{n=2}^N 
  \frac{\xi(z_{n-1,j}, z_{nk})}
  {\sum_{l=1}^K \xi(z_{n-1,j}, z_{nl})}
\label{eqn:3-9}
\end{equation}

Entonces, el algoritmo EM, debe ser inicializado escogiendo algunos valores para $\pi$ y $\mathbf{A}$, considerando las restricciones que implican cada uno, pues representan ciertas probabilidades. Por tanto, se puede inicializar tanto $\pi$ como $\mathbf{A}$ con valores aleatorios, siempre y cuando cumplan con las restricciones propias de una probabilidad. 

Por último, para estimar el parámetro $\theta$, que en realidad corresponde a estimar los parámetros propios de la distribución de emisión, éstos dependen de la distribución propia de las variables observadas, aunque basta 1 observar que en \eqref{eqn:3-7} únicamente en el último término aparece $\theta$ en forma de una suma ponderada de $ln p(x_n \,|\,  \phi_k)$; y en el caso de que los parámetros $\phi_k$ sean independientes para los diferentes componentes de la mezcla o suma ponderada, entonces maximizar con respecto a esos parámetros se puede realizar de forma sencilla.

\section{Algoritmo \abf}

Se presenta ahora un algoritmo que nos permite estimar de forma eficiente tanto $\gamma(z_{nk})$ como $\xi(z_{n-1, j}, z_{nk})$ que se requieren para el \estep~ del algoritmo de EM.

Para deducir el algoritmo, primero se deben tener en cuenta varias propiedades de una cadena de Márkov, que nos permitirán simplificar varios cálculos (Ver apéndice). Además, se debe tener en cuenta que éste desarrollo es general, puesto que es independiente de las probabilidades de emisión $p(x \,|\, z)$, y entonces no importa si las variables observadas son discretas o continuas, pues lo único que se requiere es poder evaluar $p(x_n \,|\, z_n)$ para cada $z_n$, que sabemos que son discretas.

Se puede comenzar por evaluar $\gamma(z_n)$, que es la probabilidad a posteriori $p(z_n \,|\, x_1, ..., x_N)$ de $z_n$ dado un conjunto de datos $x_1, ..., x_N$. Entonces, usando el teorema de bayes se tiene que
\begin{equation}
  \gamma(z_n) = p(\mb{z}_n \,|\, \mb{X}) = 
    \frac{p(\mb{X} \,|\, \mb{z}_n) p(\mb{z}_n)}{p(\mb{X})} 
  \label{eqn:3-10}
\end{equation}
y usando la regla del producto, tenemos que
\begin{equation}
  \gamma(z_n) = \frac{
    p(x_1, ..., x_n, z_n) p(x_{n+1}, ..., x_N \,|\, z_n) 
    }
    {p(\mb{X})} = \frac{\alpha(z_n) \beta(z_n)}{p(\mb{X})}
  \label{eqn:3-11}
\end{equation}
donde usamos la siguiente notación:
\begin{align}
  \alpha(z_n) &\equiv p(x_1, ..., x_n, z_n) 
\label{eqn:3-12} \\
  \beta(z_n) &\equiv p(x_{n+1}, ..., x_N \,|\, z_n) 
  \label{eqn:3-13}
\end{align}
Se puede pensar $\alpha(z_n)$ como la probabilidad conjunta de observar toda una secuencia de datos hasta el momento $n$, además de el valor de la variable $z_n$; mientras que $\beta(z_n)$ es la probabilidad condicional para una secuencia de datos desde un momento $n$ hasta $N$, dado que se conoce $z_n$. 

Primero, desarrollamos \eqref{eqn:3-12} como sigue:
\begin{align}
  \alpha(z_n) &= p(x_1, ..., x_n, z_n)  
  \notag \\ 
  \alpha(z_n) &= p(x_1, ..., x_n \,|\, z_n)  p(z_n) 
  \notag \\ 
  \alpha(z_n) &= p(x_1, ..., x_{n-1} \,|\, z_n) p(x_n \,|\, z_n)  p(z_n) 
  \notag \\ 
  \alpha(z_n) &= p(x_1, ..., x_{n-1}, z_n) p(x_n \,|\, z_n)
  \notag
\end{align}
donde primero factorizamos $p(z_n)$ y luego $p(x_n \,|\, z_n)$ del resto, puesto que $x_n \perp x_1, ... , x_{n-1} \,|\, z_n$; para luego volver a juntar $p(z_n)$
usando el Teorema de Bayes.

Luego, marginalizando sobre $z_1$, podemos escribir
\begin{align}  
  \alpha(z_n) &= p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    p(x_1, ..., x_{n-1}, z_{n-1}, z_n) 
    \notag \\ 
  \alpha(z_n) &= p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    p(x_1, ..., x_{n-1}, z_n \,|\, z_{n-1}) p(z_{n-1})
    \notag \\ 
  \alpha(z_n) &= p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    p(x_1, ..., x_{n-1} \,|\, z_{n-1}) p(z_n \,|\, z_{n-1}) p(z_{n-1})
    \notag \\ 
  \alpha(z_n) &= p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    p(x_1, ..., x_{n-1}, z_{n-1}) p(z_n \,|\, z_{n-1})
    \label{eqn:3-14}
\end{align}
y usando que $z_{n-1} \perp x_1, ... , x_{n-1} \,|\, z_n$, podemos seguir el mismo procedimiento para llegar a \eqref{eqn:3-14}; y por último, podemos usar la definición de \eqref{eqn:3-12} para el primer factor de la suma, llegando a que
\begin{equation}
  \alpha(z_n) = p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    \alpha(z_{n-1}) p(z_n \,|\, z_{n-1})
    \label{eqn:3-15}
\end{equation}

Con lo que se obtiene una forma recursiva para calcular $\alpha(z_n)$ a partir de $\alpha(z_{n-1})$ para cuaquier $n$, excepto para $n = 1$; pues no se tiene definido un $z_0$. Por esto mismo, podemos definir el caso inicial $\alpha(z_1)$ usando \eqref{eqn:3-12} y entonces resultaría:
\begin{equation}
  \alpha(z_1) = p(x_1, z_1) = p(z_1) p(x_1 \,|\, z_1) 
  \label{eqn:3-16}
\end{equation}

De la misma manera, para el caso de $\beta(z_n)$ desarrollando a partir de  \eqref{eqn:3-13}
\begin{align}
  \beta(z_n) &= p(x_{n+1}, ..., x_N \,|\, z_n)
    \notag \\
  \beta(z_n) &= \sum_{z_{n+1}} p(x_{n+1}, ..., x_N, z_{n+1} \,|\, z_n)
    \notag \\
  \beta(z_n) &= \sum_{z_{n+1}} p(x_{n+1}, ..., x_N \,|\, z_n, z_{n+1}) 
    p(z_{n+1} \,|\, z_n)
    \notag \\
  \beta(z_n) &= \sum_{z_{n+1}} p(x_{n+1}, ..., x_N \,|\, z_{n+1}) 
    p(z_{n+1} \,|\, z_n)  
    \notag 
\end{align}
donde primero agregamos la variable $z_{n+1}$ y marginalizamos con respecto a ella, para luego factorizar $p(z_{n+1} \,|\, z_n)$. Después, considerando que 
$x_{n+1}, ..., x_N \perp z_n \,|\, z_{n+1}$, podemos simplificar la expresión.

A partir de ahí, podemos factorizar $p(x_{n+1} \,|\, z_{n+1})$ con lo que llegamos a 
\begin{equation}  
  \beta(z_n) = \sum_{z_{n+1}} p(x_{n+2}, ..., x_N \,|\, z_{n+1}) 
    p(x_{n+1} \,|\, z_{n+1}) p(z_{n+1} \,|\, z_n)    
    \label{eqn:3-17}
\end{equation}
donde usando \eqref{eqn:3-13} obtenemos de nuevo una forma recursiva para $\beta(z_n)$
\begin{equation}  
  \beta(z_n) = \sum_{z_{n+1}} \beta(z_{n+1})
    p(x_{n+1} \,|\, z_{n+1}) p(z_{n+1} \,|\, z_n)    
    \label{eqn:3-18}
\end{equation}
que en este caso dependería del valor de $\beta(z_{n+1})$ y aplicaría para cualquier $n$, excepto cuando $n = N$. 

Para este caso, igual partiríamos de la definición en \eqref{eqn:3-11}
\begin{equation}
  p(z_n \,|\, \bf{X}) = \frac{p(\bf{X}, z_N) \beta(z_N)} {p(\bf{X})}
  \label{eqn:3-19}
\end{equation}
de donde se obtiene que 
\begin{equation}
  \beta(z_N) = 1
  \label{eqn:3-20}
\end{equation}

\subsection{Factor de escala}
\label{sec:escala}

Para la implementación, se tiene que considerar un problema común del algoritmo de backward-forward: como ya se mencionó, en el proceso recursivo para calcular cada $\alpha(z_n)$ se utilizan los previamente calculados $\alpha(z_{n-1})$, además de unas multiplicaciones por un par de probabilidades. Puesto que cada probabilidad es por definición menor o igual a 1, y que esta operación se realiza iterativamente para cada estado $n$, se tiene entonces que los valores de $\alpha(z_n)$ decrecerán rápidamente, y llegará un momento en el que no se puedan representar en una computadora (por los límites tanto de la notación punto flotante como del doble punto flotante).

Comúnmente, cuando se tienen problemas de precisión, se suele tomar el logaritmo, y así se amplia el rango, evitando posibles underflows. Sin embargo, para el caso presentado, no es posible realizar esto, pues tanto para $\alpha(z_n)$ como $\beta(z_n)$ se manejan sumas de números pequeños, y entonces no tiene sentido usar el logaritmo; pues el logaritmo no se aplicaría directamente sobre esos valores que pudieran ser pequeños; sino sobre la suma de ellos.

Se propone entonces manejar las probabilidades de forma reescalada. Originalente, $\alpha(z_n)$ representa la probabilidad conjunta de todas las variables observadas $x_1, ..., x_n$ junto con la variable latente $z_n$. Se usará entonces $\hat \alpha(z_n)$ como la probabilidad condicional de la variable latente $z_n$ dadas todas las observaciones antes mencionadas. Es decir:
\begin{equation}
  \hat \alpha(z_n) = p(z_n \,|\, x_1, ..., x_n )
    = \frac{\alpha(z_n)}{p(x_1, ..., x_n)}
  \label{eqn:3-21}
\end{equation}
El orden entre las cantidades se mantendrá, puesto que se dividirá entre la probabilidad conjunta de las variables observadas $p(x_1, ..., x_n)$.

Como en algún momento nos será útil regresar del espacio escalado al espacio original de las variables, es importante calcular estos factores de escala para cada una de las $\hat \alpha(z_n)$.
\begin{equation}
  c_n = p(x_n \,|\, x_1, ..., x_{n-1})
  \label{eqn:3-22}
\end{equation}
y entonces podemos calcular el factor de escalamiento usando la regla del producto
\begin{equation}
  p(x_1, ..., x_n) = \prod_i^n c_i 
  \label{eqn:3-23}
\end{equation}
y entonces, para obtener $\alpha(z_n)$ a partir de $\hat \alpha(z_n)$ se procede de la siguiente manera:
\begin{align}
  \alpha(z_n) &= p(x_1, ..., x_n, z_n) 
    = p(x_1, ..., x_n) p(z_n \,|\, x_1, ..., x_n ) \notag \\
    &= \left( \prod_i^n c_i \right) \hat \alpha(z_n)    
  \label{eqn:3-24}
\end{align}

De la misma manera, la forma recursiva que se había obtenido en \eqref{eqn:3-15} se puede reescribir de la siguiente manera:
\begin{equation}
  c_n \alpha(z_n) = p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    \hat \alpha(z_{n-1}) p(z_n \,|\, z_{n-1})
    \label{eqn:3-25}
\end{equation}
por lo que ahora, a cada paso de la recursión al calcular $\hat \alpha(z_{n-1})$, se debe calcular también $c_n$ e ir almacenando los coeficientes que normalizan a $\alpha(z_n)$.

Ahora, para reescalar $\beta(z_n)$ usando los coeficientes $c_n$ se tendría que
\begin{equation}
  \beta(z_n) = \left( \prod_i^n c_i \right) \hat \beta(z_n)
  \label{eqn:3-26}
\end{equation}
donde 
\begin{equation}
  \hat \beta(z_n) = 
    \frac{p(x_{n+1}, ..., x_N \,|\, z_n)}
    {p(x_{n+1}, ..., x_N \,|\, x_1, ..., x_n)}
  \label{eqn:3-27}
\end{equation}
y por lo tanto tampoco presentaría problemas numéricos el cálculo de $\hat \beta{z_n}$, puesto que vuelve a ser un cociente de probabilidades. En este caso, de la condicional de las variables observadas desde $x_{n+1}, ..., x_N$ dada la variable latente $z_n$ sobre la probabilidad condicional de las mismas variables observadas dadas todas las variables anteriores a $x_{n+1}$.

Entonces, para calcular recursivamente los valroes de $\hat \beta(z_n)$, se deriva que 
\begin{equation}
  c_{n+1} \hat \beta(z_n) = \sum_{z_{n+1}} \hat \beta(z_{n+1})
    p(x_{n+1} \,|\, z_{n+1}) p(z_{n+1} \,|\, z_n)    
\end{equation}
donde usamos los coeficientes de reescalaciemtno que ya habíamos calculado (y almacenado) junto con los valores de $\hat \alpha(z_n)$.

%Por último, para calcular la verosimilitud.
\section{Selección de número de interlocutores usando bootstrap}
...
