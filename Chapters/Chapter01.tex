%!TEX root = ../Base.tex

%************************************************
\chapter{Introducción}\label{ch:chap1}
%************************************************

%\epigraphhead[70]{
%\epigraph{Essentially, all models are wrong, but some are useful.}
%         {George E. P. Box}}

\section{Definición del problema} 
\label{sec:definicion}
        
En los últimos años la tarea de \SD~ se ha vuelto una parte importante de diferentes procesos que se realizan con las grabaciones de audio, tales como la identificación y navegación por segmentos en específico, además de la búsqueda y recuperación de información en grandes volúmenes de secuencias de audio.

La investigación desarrollada referente a \sd~ se ha guiado principalmente de acuerdo a la financiación existente para proyectos específicos. Hasta principios de la década de 1990, el trabajo de investigación se concentraba en trabajar con grabaciones telefónicas. Principalmente se usaba para segmentar la conversación, así como etapa de pre-procesamiento para luego realizar reconocimiento y/o transcripción del habla.

Para la década del 2000, las aplicaciones fueron cambiando, a la par que aumentaba la capacidad disponible de almacenamiento; por lo que creció el interés de mantener un registro de forma automática de noticieros televisivos  y transmisiones de radio a lo largo de todo el planeta. Entre la información más útil que se registraba de las grabaciones, era la transcripción del diálogo, meta-etiquetas referentes al contenido así como la segmentación y le orden de las personas que intervienen en la grabación.

A principios del año 2002, empezaron a surgir varios proyectos de investigación cuya principal intención era mejorar la comunicación interpersonal, y en especial la que ocurre a larga distancia y de forma multimodal. La investigación y desarrollo se enfocó en extracción del contenido y su etiquetación de acuerdo a las personas que participan, ya sea para mantener un archivo histórico, o para fácil disposición de personas interesadas en su contenido.

Debido a la creciente investigación en estos campos, el \ac{NIST}, ha organizado un sistema de oficial de evaluaciones que permita  unificar así como dirigir el esfuerzo de los investigadores que trabajan en esta área; al tener una manera precisa de comparar las diferentes metodologías en las que trabajan. Primero, en el 2002 las pruebas consistían en grabaciones correspondientes a noticieros, y para el 2004 se empezaron a incluir pruebas con grabaciones de reuniones, que resultaban ser la principal aplicación en esos años.

Una gran diferencia entre ambos tipos de entornos, es que mientras en un noticiero se suelen tener preparados los diálogos que se dirán e incluso se leen las noticias; en el caso de las reuniones la conversación es más espontánea y puede suceder que dos personas hablen al mismo tiempo. 

Otra característica diferente, es que mientras en un noticiero cada participante suele tener un micrófono de solapa o hay micrófonos ambientales, éstos suelen ser de calidad, por lo que no el audio de la grabación es mucho mejor y no hay mucho ruido presente en la señal. 

Por otro lado, para el caso de las reuniones, el ambiente no suele ser tan controlado, y puede haber un mayor ruido ambiental; además de que tanto al disposición de los micrófonos así como su calidad no siempre son la mejor, agregando interferencia o redundancia innecesaria a la señal.

Por eso, se considera el caso de reuniones como el escenario completo para las tareas involucradas con reconocimiento del habla; por la complejidad y los diferentes problemas que se pueden presentar.

En este trabajo de tesis se abordará el problema usando un escenario similar al del noticiero, en donde no hay ruido ambiental y los diálogos son más o menos continuos, además de que los participantes no se interrumpen al hablar.

\section{Principales enfoques}
\label{sec:previo}

De acuerdo al trabajo desarrollado hasta ahora, se puede distinguir que hay dos grandes enfoques que se usan para \sd: \bu~ (de abajo a arriba) y \td~ (de arriba a abajo). De forma general, se consideran \bu~ las metodologías en las que se inicia la estimación con pocos clústers (e incluso un sólo segmento), y \td~ aquellas en las que se inicia la estimación con muchos más clústers de los que se esperan encontrar.

Ambos enfoques iteraran hasta converger a un número de clústers óptimo, en que cada grupo debe corresponder a un interlocutor.

Para ambas estrategias se suelen usar \acp{HMM} donde cada estado se representa muchas veces como Modelos de Mezclas de \ac{GMM} y corresponde a cada interlocutor. Las matrices de transición entre estados representan el cambio entre la persona que está hablando; mientras que las matrices de una emisión corresponden a la probabilidad de los interlocutores de \textit{decir} cada una de las \textit{palabras} que se definan.

Es importante remarcar que con \textit{decir una palabra} no necesariamente se refiere a la acción de que una persona pronuncie una palabra; sino que se definirá un \textit{diccionario de palabras} que en realidad es conjunto de vectores de características que representen la señal de audio de forma discreta; y cada interlocutor tendrá una probabilidad de emisión asociada para cada uno de estos vectores.

\section{Trabajos previos}

En el trabajo de Anguera~et~al.~\cite{AngueraMiro2012} se hace un profundo análisis sobre el estado del arte hasta hace un año, y se mencionan las principales características de cada uno de estos trabajos, que a continuación se resumen.

Dentro de los trabajos que usan un enfoque \bu~ se encuentran por ejemplo el de Anguera~et~al.~\cite{AngueraMiro2006}, en donde se propone una medida de similitud entre clústers utilizando una variante de \ac{BIC} para decidir qué pares de clústers agrupar, así como para establecer un criterio de paro.

En el trabajo de Wooters~et~al.~\cite{Wooters2007}, también proponen una métrica basada en \ac{BIC} para la aglomeración de los grupos, pero se enfocan principalmente en mejorar una etapa de pre-procesamiento de la señal para detectar cuando alguien habla o no habla en la grabación. Esto es esencial cuando por ejemplo, se puede tener segmentos musicales o momentos en los que el ruido.

Por otro lado, en el trabajo de Nguyen~et~al.~\cite{Nguyen2009} se presentan dos funciones objetivo que buscan maximizar la distancia intra-clase y la distancia inter-clase y que automáticamente deducen el número óptimo de grupos para esto. Después realizan un proceso de aglomeración jerárquico, pero en un subespacio espectral en que sean separables más fácilmente los interlocutores.

Mencionando algunos de los trabajos que son del tipo \td, se tiene por ejemplo a Meignier~et~al.~\cite{Meignier2001} quien propone un sistema conformado por un \ac{EHMM}, en el que mediante un proceso iterativo se van detectando y agregando interlocutores al modelo propuesto. El método propuesto busca reducir las falsas detecciones al incorporar información al sistema tan pronto 
como sea detectada. 

En el trabajo de Fredoulle~et~al.~\cite{Fredouille2007} también proponen un sistema en el que se usa un \ac{EHMM} para la estimación de parámetros, pero además realizan una etapa de pre-procesamiento más extensa: primero usan un \ac{HMM} de dos estados para diferenciar los silencios de la actividad de los interlocutores y luego mediante una ventana movible evalúan cuándo es más probable que haya cambio entre los hablantes, de acuerdo al Generalized Likelihood Ratio. A partir de esa información es como delimitan más el problema, y sólo tienen que buscar cada segmento encontrado a qué interlocutor corresponde.

Además, en otro trabajo de Fredoulle~et~al.~\cite{Fredouille2009} presentan el sistema \td~ anteriormente usado pero ahora se enfocan en el uso de múltiples micrófonos a diferentes distancias para obtener más información y mejorar la etapa de segmentación. También, en este sistema descartan la etapa de pre-segmentación que anteriormente se había propuesto para encontrar los posibles cambios entre interlocutores. 

Por último, en la misma línea de trabajo, Bozonnet~et~al.~\cite{Bozonnet2010} muestran más 

\section{Contribuciones}

Como contribuciones principales de este trabajo se encuentran la proposición de un modelo sencillo para la detección y segmentación de interlocutores en una grabación de audio.

Esencialmente, el trabajo realizado se centra en la selección adecuada del número de estados ocultos o participantes de la cadena de Márkov modelada, donde a través de un análisis de sensibilidad se encuentra un valor de $\lambda$ que penaliza de forma adecuada la log-verosimilitud en la función de costo propuesta. 

Además, mediante pruebas de hipótesis, y realizando bootstrap paramétrico se comprueba la certeza del modelo seleccionado :).