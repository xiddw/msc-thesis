%!TEX root = ../Thesis.tex

%************************************************
\chapter{Introducción}\label{ch:chap1}
%************************************************

\epigraphhead[70]{
\epigraph{Despacio. Al fin y al cabo tenemos toda la vida por delante.}
{Juan Rulfo.}}

\section{Definición del problema} 
\label{sec:definicion}
        
En este trabajo de tesis se abordará el problema de \SD, que consiste en identificar el número de interlocutores que participan en una grabación de audio, y además encontrar en qué segmentos de la grabación habla cada persona.

Para esta tarea, se considera que se tiene una señal de audio con información de nuestro interés, y se requiere segmentar respecto a las personas que participan en la grabación. Este proceso involucra, por una parte, encontrar el número total de personas que hablan en la conversación; y por otro lado, para cada persona propuesta se debe identificar los momentos en los que habla.

Estos dos sub-procesos se pueden realizar en diferente orden, dependiendo de la metodología utilizada. Se puede por ejemplo, tratar de inferir primero cuántas personas hablan en la secuencia de audio, y luego segmentar la grabación de acuerdo a este número de personas; o también ir segmentando la grabación y a partir de ahí cuántos son los estados posibles para la grabación de audio.


El problema en general de \sd es muy amplio, y puede presentarse muchos entornos que dificulten la tarea:
\begin{enumerate}
\item Dos personas pueden hablar al mismo tiempo, por lo que hay que considerar cierta incertidumbre adicional en el modelo.
\item En el lugar donde se realizó la grabación puede haber mucho ruido ambiental o música de fondo, por lo que es necesario realizar una etapa de pre-procesamiento para eliminar los segmentos innecesarios.
\item Para algunos tipos grabaciones, habrá momentos que serán difíciles de asignar a un interlocutor en específico: cuando tose, se ríe o estornuda alguien, por ejemplo.
\item Puede haber múltiples micrófonos presentes en la grabación, por lo que si se quiere utilizar toda la información disponible se deben considerar los posibles retrasos entre las diferentes fuentes.
\item La conversación entre los interlocutores no necesariamente está planeada, por lo que puede ser irregular el porcentaje de participación de cada persona. 
\item Se pueden presentar algunas secuencias en que el cambio entre interlocutores sea muy rápido. 
\end{enumerate}

Por ello, el trabajo se acotó en varios de estos aspectos. Para tener un mayor control tanto en el contenido como en el medio de la grabación de audio, se utilizó un sintetizador de voz para simular de forma artificial conversaciones entre varias personas tanto hombres como mujeres, en dos idiomas: inglés y español. Esto permitió además que se pudiera obtener la secuencia original de forma mucho más sencilla.

\section{Motivación}
\label{sec:lemotiv}

En los últimos años la tarea de \SD~ se ha vuelto una parte importante de diferentes procesos que se realizan con las grabaciones de audio, tales como la identificación y navegación por segmentos en específico, además de la búsqueda y recuperación de información en grandes volúmenes de secuencias de audio.

La investigación desarrollada referente a \sd~ se ha guiado principalmente de acuerdo al financiamiento existente para proyectos específicos. Hasta principios de la década de 1990, el trabajo de investigación se concentraba en trabajar con grabaciones telefónicas. Principalmente se usaba para segmentar la conversación, así como etapa de pre-procesamiento para luego realizar reconocimiento y/o transcripción del habla.

Para la década del 2000, las aplicaciones fueron cambiando, a la par que aumentaba la capacidad disponible de almacenamiento; por lo que creció el interés de mantener un registro de forma automática de noticieros televisivos  y transmisiones de radio a lo largo de todo el planeta. Entre la información más útil que se registraba de las grabaciones, era la transcripción del diálogo, meta-etiquetas referentes al contenido así como la segmentación y le orden de las personas que intervienen en la grabación.

A principios del año 2002, empezaron a surgir varios proyectos de investigación cuya principal intención era mejorar la comunicación interpersonal, y en especial la que ocurre a larga distancia y de forma multimodal. La investigación y desarrollo se enfocó en extracción del contenido y su etiquetación de acuerdo a las personas que participan, ya sea para mantener un archivo histórico, o para fácil disposición de personas interesadas en su contenido.

Debido a la creciente investigación en estos campos, el \ac{NIST}, ha organizado un sistema de oficial de evaluaciones que permita  unificar así como dirigir el esfuerzo de los investigadores que trabajan en esta área; al tener una manera precisa de comparar las diferentes metodologías en las que trabajan. Primero, en el 2002 las pruebas consistían en grabaciones correspondientes a noticieros, y para el 2004 se empezaron a incluir pruebas con grabaciones de reuniones, que resultaban ser la principal aplicación en esos años.

Una gran diferencia entre ambos tipos de entornos, es que mientras en un noticiero se suelen tener preparados los diálogos que se dirán e incluso se leen las noticias; en el caso de las reuniones la conversación es más espontánea y puede suceder que dos personas hablen al mismo tiempo. 

Otra característica diferente, es que mientras en un noticiero cada participante suele tener un micrófono de solapa o hay micrófonos ambientales, éstos suelen ser de calidad, por lo que no el audio de la grabación es mucho mejor y no hay mucho ruido presente en la señal. 

Por otro lado, para el caso de las reuniones el ambiente no suele ser tan controlado, y puede haber un mayor ruido ambiental; además de que tanto al disposición de los micrófonos así como su calidad no siempre son la mejor, agregando interferencia o redundancia innecesaria a la señal.

Por eso, se considera el caso de reuniones como el escenario completo para las tareas involucradas con reconocimiento del habla; por la complejidad y los diferentes problemas que se pueden presentar.

\section{Contribuciones}

Las principales contribuciones de este trabajo se enumeran a continuación:

\begin{enumerate}
\item Se implementó el algoritmo \ac{BW} en Matlab, con funciones críticas desarrolladas en C.
\item Se propuso un método de selección de modelo en dos etapas: primero usando una versión de \acf{BIC} regularizada, para escoger un subconjunto de soluciones más probables a partir del conjunto de modelos propuestos; luego, como segunda etapa una prueba de hipótesis usando el estadístico \acf{LLR}, para seleccionar dentro de los modelos más probables a la solución ganadora.
\item Se implementó un algoritmo para generación, ajuste automático de modelos y selección de mejor solución de acuerdo a las métricas establecidas en el \autoref{ch:chap5}.
\end{enumerate}

Esencialmente, el trabajo realizado se centra en la selección adecuada del número de estados ocultos o participantes de la cadena de Márkov modelada, donde a través la metodología propuesta, y utilizando varias técnicas como: \ac{BIC} regularizado, bootstrap paramétrico y prueba de hipótesis se encuentra el modelo solución correspondiente.

\section{Principales enfoques}
\label{sec:previo}

De acuerdo al trabajo desarrollado hasta ahora, se puede distinguir que hay dos grandes enfoques que se usan para \sd: \bu~ (de abajo a arriba) y \td~ (de arriba a abajo). De forma general, se consideran \bu~ las metodologías en las que se inicia la estimación con pocos clústers (e incluso un sólo segmento), y \td~ aquellas en las que se inicia la estimación con muchos más clústers de los que se esperan encontrar.

Ambos enfoques iteraran hasta converger a un número de clústers óptimo, en que cada grupo debe corresponder a un interlocutor.

Para ambas estrategias se suelen usar \acp{HMM} donde cada estado se representa muchas veces como Modelos de Mezclas de \ac{GMM} y corresponde a cada interlocutor. Las matrices de transición entre estados representan el cambio entre la persona que está hablando; mientras que las matrices de una emisión corresponden a la probabilidad de los interlocutores de \textit{decir} cada una de las \textit{palabras} que se definan.

Es importante remarcar que con \textit{decir una palabra} no necesariamente se refiere a la acción de que una persona pronuncie una palabra; sino que se definirá un \textit{diccionario de palabras} que en realidad es conjunto de vectores de características que representen la señal de audio de forma discreta; y cada interlocutor tendrá una probabilidad de emisión asociada para cada uno de estos vectores.

\section{Trabajos previos}

En el trabajo de Anguera~et~al.~\cite{AngueraMiro2012} se hace un profundo análisis sobre el estado del arte hasta hace un año, y se mencionan las principales características de cada uno de estos trabajos, que a continuación se resumen.

Dentro de los trabajos que usan un enfoque \bu~ se encuentran por ejemplo el de Anguera~et~al.~\cite{AngueraMiro2006}, en donde se propone una medida de similitud entre clústers utilizando una variante de \ac{BIC} para decidir qué pares de clústers agrupar, así como para establecer un criterio de paro.

En el trabajo de Wooters~et~al.~\cite{Wooters2007}, también proponen una métrica basada en \ac{BIC} para la aglomeración de los grupos, pero se enfocan principalmente en mejorar una etapa de preprocesamiento de la señal para detectar cuando alguien habla o no habla en la grabación. Esto es esencial cuando por ejemplo, se puede tener segmentos musicales o momentos en los que el ruido.

Por otro lado, en el trabajo de Nguyen~et~al.~\cite{Nguyen2009} se presentan dos funciones objetivo que buscan maximizar la distancia intra-clase y la distancia inter-clase y que automáticamente deducen el número óptimo de grupos para esto. Después realizan un proceso de aglomeración jerárquico, pero en un subespacio espectral en que sean separables más fácilmente los interlocutores.

Mencionando algunos de los trabajos que son del tipo \td, se tiene por ejemplo a Meignier~et~al.~\cite{Meignier2001} quien propone un sistema conformado por un \ac{EHMM}, en el que mediante un proceso iterativo se van detectando y agregando interlocutores al modelo propuesto. El método propuesto busca reducir las falsas detecciones al incorporar información al sistema tan pronto 
como sea detectada. 

En el trabajo de Fredoulle~et~al.~\cite{Fredouille2007} también proponen un sistema en el que se usa un \ac{EHMM} para la estimación de parámetros, pero además realizan una etapa de pre-procesamiento más extensa: primero usan un \ac{HMM} de dos estados para diferenciar los silencios de la actividad de los interlocutores y luego mediante una ventana movible evalúan cuándo es más probable que haya cambio entre los hablantes, de acuerdo al Generalized Likelihood Ratio. A partir de esa información es como delimitan más el problema, y sólo tienen que buscar cada segmento encontrado a qué interlocutor corresponde.

Además, en otro trabajo de Fredoulle~et~al.~\cite{Fredouille2009} presentan el sistema \td~ anteriormente usado pero ahora se enfocan en el uso de múltiples micrófonos a diferentes distancias para obtener más información y mejorar la etapa de segmentación. También, en este sistema descartan la etapa de pre-segmentación que anteriormente se había propuesto para encontrar los posibles cambios entre interlocutores. 

Por último, en la misma línea de trabajo utilizando \ac{EHMM}, Bozonnet~et~al.~\cite{Bozonnet2010} muestran algunas mejoras en el ajuste de parámetros utilizados al momento de entrenar el modelo; pero además de que agregan una etapa de purificación después de la clasificación y segmentación de la secuencia, re-evaluando la pertenencia de intervalos. Esta etapa de reasignación en metodologías \td~ muestra un buen desempeño, pues se hace la purificación con respecto a segmentos en los que un interlocutor es dominante respecto a los demás.

