%!TEX root = ../Thesis.tex

\chapter{Selección de modelo}

\epigraphhead[70]{
\epigraph{Choose well. Your choice is brief, and yet endless.}
{Johann Wolfgang von Goethe}}

Puesto que el problema abarca también el detectar cuántos personas están involucrados en la grabación, y hasta ahora se ha considerado que se dispone de esta información, es necesario inferir de alguna manera cuántos interlocutores participan.

La contribución principal de este trabajo de tesis está en la selección de modelo propuesta, utilizando varias técnicas tanto bayesianas como frecuentistas para respaldar la elección realizada.

Como mencionan Claeskens y Hjort \cite{Claeskens2010}, hay varios aspectos importantes que considerar antes de abordar el problema de selección de modelos: 

\begin{enumerate}
\item Los modelos son aproximaciones: Cuando se usan modelos, se tiene que considerar que la realidad observada suele ser mucho más compleja que los modelos propuestos. No necesariamente existirá un modelo correcto 

\item Sesgo-Varianza: Se refiere a balancear tanto la simplicidad del modelo (pocos parámetros a estimar, lo que implicaría una menor variabilidad, aunque con cierto sesgo) contra la complejidad (introducir más parámetros al modelo, )
\end{enumerate}

Para esto, se necesitan tener presentes varios conceptos: 

\section{Funciones de penalización}

Una estrategia sencilla para la selección de modelo es elegir el candidato con la más grande probabilidad dados los datos. 

Comparar directamente los valores máximos alcanzados de log-verosimilitud para diferentes modelos no siempre es un criterio lo suficientemente bueno para la comparación de modelos. Al incluirse más parámetros en un modelo, la máxima log-verosimilitud también aumentará, pues el modelo se sobre-ajustará; por lo que no siempre será la mejor elección. 

Escoger el modelo con la mayor log-verosimilitud equivaldría a siempre elegir el modelo con más parámetros; lo que puede significar que tiene un buen poder predictivo para los datos que se usaron de entrenamiento, pero que probablemente en pruebas con otros datos diferentes no tendrá un buen desempeño.

Para evitar esto, se han diseñado funciones de penalización que permiten 

Entre las más comunes, se encuentran por ejemplo el \acf{AIC} o el \acf{BIC}, que se encargan de selección de modelo a partir de la estimación de máxima verosimilitud de los datos, así como también penalizan el número de parámetros libres que necesita el modelo.


\subsection{BIC}

\subsection{Otras}

\section{Bootstrap paramétrico}

\section{Selección de modelo usando bootsrap con likelihood ratio testing}

Para realizar esto, primero se usará la técnica conocida como bootstrap paramétrico para comparar el modelo correspondiente de $d$ estados contra el de $d+1$ estados ocultos.

La prueba que se realiza es comparando el \ac{MLE} $\hat \theta^{(d)}$ y $\hat \theta^{(d+1)}$ de los modelos de $d$ y $d+1$ estados respectivamente. Para la comparación se usa la estadística \ac{LLR} que corresponde a la diferencia de las log-verosimilitudes mencionadas
\begin{equation}
  LR^{(d)}_{obs} = log \frac{L(\hat \theta^{(d+1)}; y_{1:n})}{L(\hat \theta^{(d)}; y_{1:n})} =
    log L(\hat \theta^{(d+1)}; y_{1:n}) - 
    log L(\hat \theta^{(d)}; y_{1:n})
\end{equation}

Para calcular el \ac{MLE} de un modelo, se estimó la verosimilitud varias veces con diferentes parámetros iniciales aleatorios. Se iteró el algoritmo \ac{EM} hasta convergencia, un numero $iter_{hmm}$ fijo de iteraciones, esto para evitar el estancamiento del algoritmo en un máximo local, y obtener así una buena estimación de la máxima verosimilitud del modelo.

Se usó entonces como \ac{MLE} del modelo la máxima verosimilitud correspondiente a los mejores parámetros estimados y que se denotó por $LLR_{obs}$.

Ahora, para hacer la prueba con boostrap, simularemos 

\begin{algorithm}[tp]
   \caption{Muestreo ancestral para un HMM}
   \label{alg:ancsamp}
\begin{algorithmic}
   \STATE {\bfseries Input:} \\
   núm. de estados $N$, núm. de muestras en el tiempo $T$ \\
   núm. de posibles valores en el diccionario $K$, \\
   $ \pi \in \mathcal{R}^{N}; ~~ \pi_j = p(z_{1j})$ \\
   $ \mathbf{A} \in \mathcal{R}^{N \times N}; ~~
   \mathbf{A}_{jk} = p(z_{nk} \,|\, z_{n-1, j})$ \\

   $ \mathbf{E} \in \mathcal{R}^{K \times N}; ~~
   \mathbf{E}_{jk} = p(x_{nk} \,|\, z_{n, j})$\\  
   \STATE
   \STATE $z_1 \sim Multinomial(\pi)$   
   \STATE $x_1 \sim Multinomial(\mathbf{E}_{[z_1,~:]})$

   \FOR{$i = 1 \to T$} 
    \STATE $z_t \sim Multinomial(\mathbf{A}_{[z_{t-1},~:]})$ 
    \STATE $x_t \sim Multinomial(\mathbf{E}_{[z_t,~:]})$
   \ENDFOR   
\end{algorithmic}
\end{algorithm}

\section{Selección de modelo usando BIC}

Otra manera de realizar la selección del modelo que mejor se adecua a los datos que se observan, es usar una métrica específica para la selección de modelos.

%%%%%%%%%%%%

Puesto que consideramos que dentro de nuestro espacio de modelos propuestos se encuentra el modelo solución (esto es, hay un modelo que corresponde con el número de interlocutores que participan en la grabación), resulta más natural usar \ac{BIC}.

Este criterio se calcula de la siguiente manera: 
\begin{equation}
BIC(M) = 2 log-likelihood_{max}(M) - (log n ) dim(M)
\end{equation}
para cada propuesta de modelo $M$, donde $dim(M)$ es el número estimado de parámetros libres que le corresponden, y $n$ es el tamaño de nuestra muestra de datos.

Para estimar el número de parámetros libres de nuestro modelo, se consideran todas las probabilidades que rigen al \ac{HMM}, que en este caso son: la matriz a priori o inicial, la matriz de transiciones entre los interlocutores, así como la matriz de emisión de cada persona para todo el diccionario de palabras.

Esta selección se enfoca en escoger el candidato modelo con la mayor probabilidad dados los datos, pero penalizando la complejidad de cada propuesta. Se preferirán entonces los modelos con una mayor verosimilitud que involucren la menor cantidad de parámetros posibles. 

...