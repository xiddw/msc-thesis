%!TEX root = ../Thesis.tex

\chapter{Selección de modelo}

\epigraphhead[70]{
\epigraph{``Data! Data! Data!'' he cried impatiently. 
``I can't make bricks without clay.''}{Sherlock Holmes}}

Puesto que el problema abarca también el detectar cuántos personas están involucrados en la grabación, y hasta ahora se ha considerado que se dispone de esta información, es necesario inferir de alguna manera cuántos interlocutores participan.

Para esto, se necesitan tener presentes varios conceptos: 

\section{Bootstrap paramétrico}

\section{Funciones de penalización}

Una estrategia sencilla para la selección de modelo es elegir el candidato con la más grande probabilidad dados los datos. 

\subsection{BIC}

\subsection{Otras}



\section{Selección de modelo usando bootsrap con likelihood ratio testing}

Para realizar esto, primero se usará la técnica conocida como bootstrap paramétrico para comparar el modelo correspondiente de $d$ estados contra el de $d+1$ estados ocultos.

La prueba que se realiza es comparando el \ac{MLE} $\hat \theta^{(d)}$ y $\hat \theta^{(d+1)}$ de los modelos de $d$ y $d+1$ estados respectivamente. Para la comparación se usa la estadística \ac{LLR} que corresponde a la diferencia de las log-verosimilitudes mencionadas
\begin{equation}
  LR^{(d)}_{obs} = log \frac{L(\hat \theta^{(d+1)}; y_{1:n})}{L(\hat \theta^{(d)}; y_{1:n})} =
    log L(\hat \theta^{(d+1)}; y_{1:n}) - 
    log L(\hat \theta^{(d)}; y_{1:n})
\end{equation}

Para calcular el \ac{MLE} de un modelo, se estimó la verosimilitud varias veces con diferentes parámetros iniciales aleatorios. Se iteró el algoritmo \ac{EM} hasta convergencia, un numero $iter_{hmm}$ fijo de iteraciones, esto para evitar el estancamiento del algoritmo en un máximo local, y obtener así una buena estimación de la máxima verosimilitud del modelo.

Se usó entonces como \ac{MLE} del modelo la máxima verosimilitud correspondiente a los mejores parámetros estimados y que se denotó por $LLR_{obs}$.

Ahora, para hacer la prueba con boostrap, simularemos 

\begin{algorithm}[tp]
   \caption{Muestreo ancestral para un HMM}
   \label{alg:ancsamp}
\begin{algorithmic}
   \STATE {\bfseries Input:} \\
   núm. de estados $N$, núm. de muestras en el tiempo $T$ \\
   núm. de posibles valores en el diccionario $K$, \\
   $ \pi \in \mathcal{R}^{N}; ~~ \pi_j = p(z_{1j})$ \\
   $ \mathbf{A} \in \mathcal{R}^{N \times N}; ~~
   \mathbf{A}_{jk} = p(z_{nk} \,|\, z_{n-1, j})$ \\

   $ \mathbf{E} \in \mathcal{R}^{K \times N}; ~~
   \mathbf{E}_{jk} = p(x_{nk} \,|\, z_{n, j})$\\  
   \STATE
   \STATE $z_1 \sim Multinomial(\pi)$   
   \STATE $x_1 \sim Multinomial(\mathbf{E}_{[z_1,~:]})$

   \FOR{$i = 1 \to T$} 
    \STATE $z_t \sim Multinomial(\mathbf{A}_{[z_{t-1},~:]})$ 
    \STATE $x_t \sim Multinomial(\mathbf{E}_{[z_t,~:]})$
   \ENDFOR   
\end{algorithmic}
\end{algorithm}

\section{Selección de modelo usando BIC}

Otra manera de realizar la selección del modelo que mejor se adecua a los datos que se observan, es usar una métrica específica para la selección de modelos.

Comparar directamente los valores máximos alcanzados de log-verosimilitud para diferentes modelos no siempre es un criterio lo suficientemente bueno para la comparación de modelos. Al incluirse más parámetros en un modelo, la máxima log-verosimilitud también aumentará, pero esto no implica que esta sea siempre la mejor elección. 

Escoger el modelo con la mayor log-verosimilitud equivaldría a siempre elegir el modelo con más parámetros; lo que puede significar que tiene un buen poder predictivo para los datos que se usaron de entrenamiento, pero que probablemente en pruebas con otros datos diferentes no  

Entre las más comunes, se encuentran por ejemplo el \acf{AIC} o el \acf{BIC}, que se encargan de selección de modelo a partir de la estimación de máxima verosimilitud de los datos, así como también penalizan el número de parámetros libres que necesita el modelo.



Puesto que consideramos que dentro de nuestro espacio de modelos propuestos se encuentra el modelo solución (esto es, hay un modelo que corresponde con el número de interlocutores que participan en la grabación), resulta más natural usar \ac{BIC}.

Este criterio se calcula de la siguiente manera: 
\begin{equation}
BIC(M) = 2 log-likelihood_{max}(M) - (log n ) dim(M)
\end{equation}
para cada propuesta de modelo $M$, donde $dim(M)$ es el número estimado de parámetros libres que le corresponden, y $n$ es el tamaño de nuestra muestra de datos.

Para estimar el número de parámetros libres de nuestro modelo, se consideran todas las probabilidades que rigen al \ac{HMM}, que en este caso son: la matriz a priori o inicial, la matriz de transiciones entre los interlocutores, así como la matriz de emisión de cada persona para todo el diccionario de palabras.

Esta selección se enfoca en escoger el candidato modelo con la mayor probabilidad dados los datos, pero penalizando la complejidad de cada propuesta. Se preferirán entonces los modelos con una mayor verosimilitud que involucren la menor cantidad de parámetros posibles. 

...