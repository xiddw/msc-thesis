%!TEX root = ../Thesis.tex

%************************************************
\section{Estimación de Máxima Verosimilitud del HMM}
%************************************************

La tarea de aprendizaje de parámetros del \ac{HMM} se refiere a encontrar, dada una secuencia de datos observados, el mejor conjunto de probabilidades de transición y emisión.

Este problema es difícil de resolver, pues no se tiene una forma analítica de resolverlo \cite{Rabiner1989}. De hecho, dada una secuencia finita de observaciones como conjunto de entrenamiento, no hay forma óptima de estimar los parámetros verdaderos del modelo, y lo más que se puede hacer, es escoger $\theta = \left( \textbf{A}, \textbf{B}, \pi \right)$ tal que $P(\textbf{X} \,|\, \theta)$ corresponda a un máximo local usando algún algoritmo tipo \ac{EM} o técnicas de descenso de gradiente. 

A continuación, se presentará el algoritmo de Baum–Welch que es básicamente \ac{EM} aplicado a una cadena de Márkov, y que nos permitirá tanto inferir los parámetros $\theta$ del \ac{HMM} así como luego recuperar la secuencia de estados.

%\section{Estimación de parámetros del HMM}
\subsection{Estimación de parámetros del HMM}

Si se tiene un conjunto de datos observados $\mb{X} = \lbrace x_1, ..., x_N \rbrace$, se pueden determinar los parámetros del \ac{HMM} usando máxima verosimilitud. La función de verosimilitud se obtiene de la distribución conjunta \eqref{eqn:2-11} al marginalizar las variables latentes.
\begin{equation}
  p(\mb{X}, \theta) = \sum_Z p(\mb{X}, \mb{Z} \,|\, \theta)
\label{eqn:3-1}
\end{equation}

Sin embargo, la función obtenida presenta algunas dificultades, pues no se puede tratar $z_n$ como si fueran variables independientes y separarlas, puesto que cada variable latente $z_n$ depende del estado anterior. Además, no es factible separar las sumas de estas $N$ variables, pues para cada una se tendría que considerar cada uno de sus $K$ posibles estados, y entonces el número de términos en la suma es del orden $K^N$, y crece exponencialmente con el largo de la cadena. Por esto y algunas otras razones, es que se descarta el estimar los parámetros del modelo de forma directa por máxima verosimilitud.

Por esto, se usará el algoritmo de \ac{EM} para maximizar la verosimilitud. Inicialmente, se hace una selección inicial de los parámetros que denotaremos como $\theta^{old}$. Luego, en el primer paso del \aem -conocido como \estep- se toman estos parámetros para encontrar la probabilidad a posteriori de las variables latentes $p(\mb{Z} \,|\, \mb{X}, \theta^{old})$, las cuales se usarán para evaluar la esperanza de la log-verosimilitud completa.

Bishop~\cite{Bishop2006} define esta esperaza en función tanto de la estimación previa de parámetros $\theta^{old}$ así como de los nuevos parámetros $\theta$ calculados:
\begin{equation}
\mc{Q}(\theta, \theta^{old}) = 
  \sum_{\mb{Z}} p(\mb{Z} \,|\, \mb{X}, \theta^{old})
  ln p(\mb{X}, \mb{Z} \,|\, \theta).
\label{eqn:3-2}
\end{equation}

Se introduce además cierta notación para simplificar las expresiones que ahora se usarán. Se usará $\gamma(z_n)$ para denotar la distribución marginal posterior de la variable latente $z_n$, y $\xi(z_{n-1}, z_n)$ para denotar la distribución conjunta posterior de dos variables latentes sucesivas, es decir: 
\begin{gather}
\gamma(z_n) = p(z_n \,|\, \mb{X}, \theta^{old}) \label{eqn:3-3} \\
\xi(z_{n-1}, z_n) = p(z_{n-1}, z_n \,|\, \mb{X}, \theta^{old}) \label{eqn:3-4}
\end{gather}

Considerando entonces que $z_n$ es un vector binario, entonces se puede extender esta notación para cada uno de los componentes de la variable latente $z_n$, es decir, para denotar la probabilidad condicional $z_{nk} = 1$. Se
tomará entonces la esperanza tanto de $z_{nk}$ como de $z_{n-1, j}, z_{nk}$ y entonces
\begin{gather}
\gamma(z_{nk}) = \mathbb{E} \left[ z_{nk} \right] = \sum_Z  \gamma(\mb{z}) z_{nk} \label{eqn:3-5} \\
\xi(z_{n-1,j}, z_{nk}) = \mathbb{E} \left[z_{n-1, j} \cdot z_{nk} \right] = \sum_Z  \gamma(\mb{z}) z_{n-1, j} 
\cdot z_{nk}
\label{eqn:3-6}
\end{gather}

Si se sustituye $p(\mb{X}, \mb{Z} \,|\, \theta)$ de \eqref{eqn:2-11} en \eqref{eqn:3-2}, así como usando las definiciones \eqref{eqn:3-5} y \eqref{eqn:3-6}, y luego desarrollando el logaritmo, se obtiene: 

\begin{equation}
\begin{split}
\mc{Q}(\theta, \theta^{old}) = 
  \sum_{k=1}^K \gamma(z_{1k}) ln \pi_k + 
  \sum_{n=2}^N \sum_{j=1}^K \sum_{k=1}^K \xi(z_{n-1,j}, z_{nk}) ln A_{jk} + \\
  \sum_{n=1}^N \sum_{k=1}^K \gamma(z_{nk}) ln p(x_n \,|\, \phi_k)
\label{eqn:3-7}
\end{split}
\end{equation}

Por lo que entonces en el \estep~ se debe evaluar tanto $\gamma(z_{nk})$ como $\xi(z_{n-1,j}, z_{nk})$ de forma eficiente para luego continuar con la segunda etapa del algoritmo.

El segundo paso, también conocido como \mstep, consiste en maximizar la función $\mc{Q}(\theta, \theta^{old})$ con respecto a cada uno de los parámetros $\theta = \lbrace \pi, \mb{A}, \phi \rbrace$ mientras que ahora $\gamma(z_{nk})$ y $\xi(z_{n-1,j}, z_{nk})$ se tratan como constantes.

Para maximizar entonces $\pi$, se deriva $\mc{Q}(\theta, \theta^{old})$ con respecto a $\pi_k$, usando multiplicadores de Lagrange para la restricción de $\sum_k \pi_k = 1$, por lo que entonces se tiene: 
\begin{equation*}
  \frac {\partial \mc{Q}(\theta, \theta^{old})}{\partial \pi_k} = 
  \frac {\partial}{\partial \pi_k} 
  \left[
    \sum_{k=1}^K \gamma(z_{1k}) ln \pi_k + \lambda (\sum_{k=1}^K \pi_k - 1) 
  \right]
\end{equation*}
y derivando y encontrando el valor de $\lambda$, para luego despejar $\pi_k$, se obtiene:
\begin{equation}
  \pi_k = \frac{\gamma(z_{1k})}{\sum_{j=1}^K \gamma(z_1j)}
\label{eqn:3-8}
\end{equation}
mientras que para maximizar $\mb{A}$, se deriva entonces $\mc{Q}(\theta, \theta^{old})$ con respecto a $A_{jk}$, considerando también las restricciones, es decir
\begin{equation*}
  \frac {\partial \mc{Q}(\theta, \theta^{old})}{\partial \pi_k} = 
  \frac {\partial}{\partial \pi_k} 
  \left[
    \sum_{n=2}^N \sum_{j=1}^K \sum_{k=1}^K \xi(z_{n-1,j}, z_{nk}) ln A_{jk} 
    + \lambda (\sum_{k=1}^K A_{jk} - 1) 
  \right]
\end{equation*}
y de la misma manera, resolviendo para $A_{jk}$ se obtiene
\begin{equation}
A_{jk} = \sum_{n=2}^N 
  \frac{\xi(z_{n-1,j}, z_{nk})}
  {\sum_{l=1}^K \xi(z_{n-1,j}, z_{nl})}
\label{eqn:3-9}
\end{equation}

Entonces, el algoritmo \ac{EM}, debe ser inicializado escogiendo algunos valores para $\pi$ y $\mathbf{A}$, considerando las restricciones que implican cada uno, pues representan ciertas probabilidades. Por tanto, se puede inicializar tanto $\pi$ como $\mathbf{A}$ con valores aleatorios, siempre y cuando cumplan con las restricciones propias de una probabilidad. 

Por último, para estimar el parámetro $\theta$, que en realidad corresponde a estimar los parámetros propios de la distribución de emisión, éstos dependen de la distribución propia de las variables observadas, aunque basta 1 observar que en \eqref{eqn:3-7} únicamente en el último término aparece $\theta$ en forma de una suma ponderada de $ln p(x_n \,|\,  \phi_k)$; y en el caso de que los parámetros $\phi_k$ sean independientes para los diferentes componentes de la mezcla o suma ponderada, entonces maximizar con respecto a esos parámetros se puede realizar de forma sencilla.

% \section{Algoritmo \abf}
\subsection{Algoritmo \abf}

Se presenta ahora un algoritmo que nos permite estimar de forma eficiente tanto $\gamma(z_{nk})$ como $\xi(z_{n-1, j}, z_{nk})$ que se requieren para el \estep~ del algoritmo de \ac{EM}.

Para deducir el algoritmo, se deben tener en cuenta varias propiedades de una cadena de Márkov, que nos permitirán simplificar varios cálculos. 

%Estas propiedades entre otras más están ennumeradas en Jordan (paper 2007) y  se pueden deducir usando el teorema de separación-D.

\hspace{-.2\textwidth}
\begin{minipage}{1.25\textwidth}
\begin{align}
p(\mb{X} \,|\, z_n) =~ &p(x_1, ..., x_n \,|\, z_n) 
  \cdot p(x_{n+1}, ..., x_N \,|\, z_n) 
\label{eqn:A-01} &\\
p(x_1, ..., x_{n-1} \,|\, x_n, z_n) =~ 
  &p(x_1, ..., x_{n-1} \,|\, z_n) 
\label{eqn:A-02} &\\
p(x_1, ..., x_{n-1} \,|\, z_{n-1}, z_n) =~ 
  &p(x_1, ..., x_{n-1} \,|\, z_{n-1}) 
\label{eqn:A-03} &\\
p(x_{n+1}, ..., x_N \,|\, z_n, z_{n+1}) =~ 
  &p(x_{n+1}, ..., x_N \,|\, z_{n+1}) 
\label{eqn:A-04} &\\
p(x_{n+2}, ..., x_N \,|\, z_{n+1}, x_{n+1}) =~ 
  &p(x_{n+2}, ..., x_N \,|\, z_{n+1})
\label{eqn:A-05} &\\ 
\begin{split}
  p(\mb{X} \,|\, z_{n-1}, z_n) =~ &p(x_1, ..., x_{n-1} \,|\, z_{n-1}) \cdot
  p(x_n \,|\, z_n) \\ &\cdot p(x_{n+1}, ..., x_N | z_n)
\end{split} \label{eqn:A-06} &\\
  p(x_{N+1} \,|\, \mb{X} ,z_{N+1}) =~ &p(x_{N+1} \,|\, z_{N+1}) 
\label{eqn:A-07} &\\
p(z_{N+1} \,|\, z_N, \mb{X}) =~ &p(z_{N+1} \,|\, z_N) 
\label{eqn:A-08}
\end{align}
\end{minipage}

donde $\mathbf{X} = \lbrace x_1, ..., x_N \rbrace$. 

Además, se debe tener en cuenta que éste desarrollo es general, puesto que es independiente de las probabilidades de emisión $p(x \,|\, z)$, y entonces no importa si las variables observadas son discretas o continuas, pues lo único que se requiere es poder evaluar $p(x_n \,|\, z_n)$ para cada $z_n$, que sabemos que son discretas.

Se puede comenzar por evaluar $\gamma(z_n)$, que es la probabilidad a posteriori $p(z_n \,|\, x_1, ..., x_N)$ de $z_n$ dado un conjunto de datos $x_1, ..., x_N$. Entonces, usando el teorema de Bayes se tiene que
\begin{equation}
  \gamma(z_n) = p(\mb{z}_n \,|\, \mb{X}) = 
    \frac{p(\mb{X} \,|\, \mb{z}_n) p(\mb{z}_n)}{p(\mb{X})} 
  \label{eqn:3-10}
\end{equation}
y usando la regla del producto, tenemos que
\begin{equation}
  \gamma(z_n) = \frac{
    p(x_1, ..., x_n, z_n) p(x_{n+1}, ..., x_N \,|\, z_n)}
    {p(\mb{X})} = \frac{\alpha(z_n) \beta(z_n)}{p(\mb{X})}
  \label{eqn:3-11}
\end{equation}
donde usamos la siguiente notación:
\begin{align}
  \alpha(z_n) &\equiv p(x_1, ..., x_n, z_n) 
\label{eqn:3-12} \\
  \beta(z_n) &\equiv p(x_{n+1}, ..., x_N \,|\, z_n) 
  \label{eqn:3-13}
\end{align}
Se puede pensar $\alpha(z_n)$ como la probabilidad conjunta de observar toda una secuencia de datos hasta el momento $n$, además de el valor de la variable $z_n$; mientras que $\beta(z_n)$ es la probabilidad condicional para una secuencia de datos desde un momento $n$ hasta $N$, dado que se conoce $z_n$. 

Primero, desarrollamos \eqref{eqn:3-12} como sigue:
\begin{align}
  \alpha(z_n) &= p(x_1, ..., x_n, z_n)  
  \notag \\ 
  \alpha(z_n) &= p(x_1, ..., x_n \,|\, z_n)  p(z_n) 
  \notag \\ 
  \alpha(z_n) &= p(x_1, ..., x_{n-1} \,|\, z_n) p(x_n \,|\, z_n)  p(z_n) 
  \notag \\ 
  \alpha(z_n) &= p(x_1, ..., x_{n-1}, z_n) p(x_n \,|\, z_n)
  \notag
\end{align}
donde se factorizo $p(z_n)$ y luego $p(x_n \,|\, z_n)$ del resto, puesto que $x_n \perp x_1, ... , x_{n-1} \,|\, z_n$; para luego volver a juntar $p(z_n)$
usando el Teorema de Bayes.

Luego, marginalizando sobre $z_{n-1}$, podemos escribir
\begin{align}  
  \alpha(z_n) &= p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    p(x_1, ..., x_{n-1}, z_{n-1}, z_n) 
    \notag \\ 
  \alpha(z_n) &= p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    p(x_1, ..., x_{n-1}, z_n \,|\, z_{n-1}) p(z_{n-1})
    \notag \\ 
  \alpha(z_n) &= p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    p(x_1, ..., x_{n-1} \,|\, z_{n-1}) p(z_n \,|\, z_{n-1}) p(z_{n-1})
    \notag \\ 
  \alpha(z_n) &= p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    p(x_1, ..., x_{n-1}, z_{n-1}) p(z_n \,|\, z_{n-1})
    \label{eqn:3-14}
\end{align}
y usando que $z_{n-1} \perp x_1, ... , x_{n-1} \,|\, z_n$, podemos seguir el mismo procedimiento para llegar a \eqref{eqn:3-14}; y por último, podemos usar la definición de \eqref{eqn:3-12} para el primer factor de la suma, llegando a que
\begin{equation}
  \alpha(z_n) = p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    \alpha(z_{n-1}) p(z_n \,|\, z_{n-1})
    \label{eqn:3-15}
\end{equation}

Con lo que se obtiene una forma recursiva para calcular $\alpha(z_n)$ a partir de $\alpha(z_{n-1})$ para cualquier $n$, excepto para $n = 1$; pues no se tiene definido un $z_0$. Por esto mismo, podemos definir el caso inicial $\alpha(z_1)$ usando \eqref{eqn:3-12} y entonces resultaría:
\begin{equation}
  \alpha(z_1) = p(x_1, z_1) = p(z_1) p(x_1 \,|\, z_1) 
  \label{eqn:3-16}
\end{equation}

De la misma manera, para el caso de $\beta(z_n)$ desarrollando a partir de  \eqref{eqn:3-13}
\begin{align}
  \beta(z_n) &= p(x_{n+1}, ..., x_N \,|\, z_n)
    \notag \\
  \beta(z_n) &= \sum_{z_{n+1}} p(x_{n+1}, ..., x_N, z_{n+1} \,|\, z_n)
    \notag \\
  \beta(z_n) &= \sum_{z_{n+1}} p(x_{n+1}, ..., x_N \,|\, z_n, z_{n+1}) 
    p(z_{n+1} \,|\, z_n)
    \notag \\
  \beta(z_n) &= \sum_{z_{n+1}} p(x_{n+1}, ..., x_N \,|\, z_{n+1}) 
    p(z_{n+1} \,|\, z_n)  
    \notag 
\end{align}
donde primero agregamos la variable $z_{n+1}$ y marginalizamos con respecto a ella, para luego factorizar $p(z_{n+1} \,|\, z_n)$. Después, considerando que 
$x_{n+1}, ..., x_N \perp z_n \,|\, z_{n+1}$, podemos simplificar la expresión.

A partir de ahí, podemos factorizar $p(x_{n+1} \,|\, z_{n+1})$ con lo que llegamos a 
\begin{equation}  
  \beta(z_n) = \sum_{z_{n+1}} p(x_{n+2}, ..., x_N \,|\, z_{n+1}) 
    p(x_{n+1} \,|\, z_{n+1}) p(z_{n+1} \,|\, z_n)    
    \label{eqn:3-17}
\end{equation}
donde usando \eqref{eqn:3-13} obtenemos de nuevo una forma recursiva para $\beta(z_n)$
\begin{equation}  
  \beta(z_n) = \sum_{z_{n+1}} \beta(z_{n+1})
    p(x_{n+1} \,|\, z_{n+1}) p(z_{n+1} \,|\, z_n)    
    \label{eqn:3-18}
\end{equation}
que en este caso dependería del valor de $\beta(z_{n+1})$ y aplicaría para cualquier $n$, excepto cuando $n = N$. 

Para este caso, igual partiríamos de la definición en \eqref{eqn:3-11}
\begin{equation}
  p(z_N \,|\, \mathbf{X}) = \frac{p(\mathbf{X}, z_N) \beta(z_n)}{p(\bf{X})}
  \label{eqn:3-19}
\end{equation}
y resolviendo para $\beta(z_N)$ se obtiene:
\begin{equation}
  \beta(z_N) = 1
  \label{eqn:3-20}
\end{equation}

%\subsection{Factor de escala}
\subsubsection{Factor de escala}
\label{sec:escala}

Para la implementación, se tiene que considerar un problema común del algoritmo de backward-forward: como ya se mencionó, en el proceso recursivo para calcular cada $\alpha(z_n)$ se utilizan los previamente calculados $\alpha(z_{n-1})$, además de unas multiplicaciones por un par de probabilidades. Puesto que cada probabilidad es por definición menor o igual a 1, y que esta operación se realiza iterativamente para cada estado $n$, se tiene entonces que los valores de $\alpha(z_n)$ decrecerán rápidamente, y llegará un momento en el que no se puedan representar en una computadora (por los límites tanto de la notación punto flotante como del doble punto flotante).

Comúnmente, cuando se tienen problemas de precisión, se suele tomar el logaritmo, y así se amplia el rango, evitando posibles desbordamientos. Sin embargo, para el caso presentado, no es posible realizar esto, pues tanto para $\alpha(z_n)$ como $\beta(z_n)$ se manejan sumas de números pequeños, y entonces no tiene sentido usar el logaritmo; pues el logaritmo no se aplicaría directamente sobre esos valores que pudieran ser pequeños; sino sobre la suma de ellos.

Se propone entonces manejar las probabilidades de forma re-escalada. Originalmente, $\alpha(z_n)$ representa la probabilidad conjunta de todas las variables observadas $x_1, ..., x_n$ junto con la variable latente $z_n$. Se usará entonces $\hat \alpha(z_n)$ como la probabilidad condicional de la variable latente $z_n$ dadas todas las observaciones antes mencionadas. Es decir:
\begin{equation}
  \hat \alpha(z_n) = p(z_n \,|\, x_1, ..., x_n )
    = \frac{\alpha(z_n)}{p(x_1, ..., x_n)}
  \label{eqn:3-21}
\end{equation}
El orden entre las cantidades se mantendrá, puesto que se dividirá entre la probabilidad conjunta de las variables observadas $p(x_1, ..., x_n)$.

Como en algún momento nos será útil regresar del espacio escalado al espacio original de las variables, es importante calcular estos factores de escala para cada una de las $\hat \alpha(z_n)$.
\begin{equation}
  c_n = p(x_n \,|\, x_1, ..., x_{n-1})
  \label{eqn:3-22}
\end{equation}
y entonces podemos calcular el factor de escalamiento usando la regla del producto
\begin{equation}
  p(x_1, ..., x_n) = \prod_i^n c_i 
  \label{eqn:3-23}
\end{equation}
y entonces, para obtener $\alpha(z_n)$ a partir de $\hat \alpha(z_n)$ se procede de la siguiente manera:
\begin{align}
  \alpha(z_n) &= p(x_1, ..., x_n, z_n) 
    = p(x_1, ..., x_n) p(z_n \,|\, x_1, ..., x_n ) \notag \\
    &= \left( \prod_i^n c_i \right) \hat \alpha(z_n)    
  \label{eqn:3-24}
\end{align}

De la misma manera, la forma recursiva que se había obtenido en \eqref{eqn:3-15} se puede reescribir de la siguiente manera:
\begin{equation}
  c_n \alpha(z_n) = p(x_n \,|\, z_n) \sum_{z_{n-1}} 
    \hat \alpha(z_{n-1}) p(z_n \,|\, z_{n-1})
    \label{eqn:3-25}
\end{equation}
por lo que ahora, a cada paso de la recursión al calcular $\hat \alpha(z_{n-1})$, se debe calcular también $c_n$ e ir almacenando los coeficientes que normalizan a $\alpha(z_n)$.

Ahora, para re-escalar $\beta(z_n)$ usando los coeficientes $c_n$ se tendría que
\begin{equation}
  \beta(z_n) = \left( \prod_i^n c_i \right) \hat \beta(z_n)
  \label{eqn:3-26}
\end{equation}
donde 
\begin{equation}
  \hat \beta(z_n) = 
    \frac{p(x_{n+1}, ..., x_N \,|\, z_n)}
    {p(x_{n+1}, ..., x_N \,|\, x_1, ..., x_n)}
  \label{eqn:3-27}
\end{equation}
y por lo tanto tampoco presentaría problemas numéricos el cálculo de $\hat \beta{z_n}$, puesto que vuelve a ser un cociente de probabilidades. En este caso, de la condicional de las variables observadas desde $x_{n+1}, ..., x_N$ dada la variable latente $z_n$ sobre la probabilidad condicional de las mismas variables observadas dadas todas las variables anteriores a $x_{n+1}$.

Entonces, para calcular recursivamente los valores de $\hat \beta(z_n)$, se deriva que 
\begin{equation}
  c_{n+1} \hat \beta(z_n) = \sum_{z_{n+1}} \hat \beta(z_{n+1})
    p(x_{n+1} \,|\, z_{n+1}) p(z_{n+1} \,|\, z_n)    
  \label{eqn:3-28}
\end{equation}
donde usamos los coeficientes de re-escalamiento que ya habíamos calculado (y almacenado) junto con los valores de $\hat \alpha(z_n)$.

Con las nuevas variables normalizadas, ya se pueden realizar todos los cálculos necesarios. 

Por ejemplo, para calcular la verosimilitud del modelo, usando \eqref{eqn:3-23} se tiene que
\begin{equation}
  p(\mb{X}) =  \prod_i^N c_i
  \label{eqn:3-29}
\end{equation}

Así como para el algoritmo de backward-forward, se pueden reescribir tanto \eqref{eqn:3-21} como \eqref{eqn:3-27} usando las nuevas variables 
\begin{align}
  \gamma(z_n) &= \hat \alpha(z_n) \hat \beta(z_n) \\
  \xi(z_{n-1}, z_n) &= c_n \hat \alpha(z_{n-1}) p(x_n \,|\, z_n) 
      p(z_n \,|\, z_{n-1}) \hat \beta(z_n) 
  \label{eqn:3-30}      
\end{align}

\subsection{Implementación}

Hasta ahora, se tiene la metodología completa para estimar los parámetros de un modelo propuesto; es decir, se considera que se sabe a priori el número de interlocutores que participan en la grabación. A partir de ello se estimarán los parámetros correspondientes del modelo.

Para la estimación de los parámetros se usa el algoritmo \ac{EM}, donde primero se proponen de forma aleatoria las probabilidades iniciales así como las matrices de transición y emisión correspondientes. Como condiciones de paro del método se establece un número fijo de iteraciones que depende del número de la longitud de la secuencia observada, además de usar una tolerancia mínima para la diferencia entre la log-verosimilitud de dos iteraciones contiguas. 

Después de tener los parámetros refinados por el algoritmo \abf, se debe proponer una técnica para escoger la segmentación resultante, lo que equivale a encontrar la secuencia de estados \textit{óptima} correspondiente a la secuencia observada.

Como menciona Rabiner \cite{Rabiner1989}, hay muchas formas en las que se puede definir la secuencia óptima, de acuerdo a los intereses que se necesitan cumplir. Un criterio puede ser por ejemplo, escoger las probabilidades marginales de las variables latentes $\gamma(z_n)$ \eqref{eqn:3-8} más probables de forma individual, es decir: 
\begin{equation}
q_k = \underset{1 <= k <= K}{arg~max}~ \gamma(z_{nk}), \quad \quad 1 <= n <= N
\label{eqn:3-31}
\end{equation}
Otra opción, puede ser usar el algoritmo de Viterbi que nos permite obtener la secuencia de estados más probable dada una secuencia observada. Por diseño, se escogió el primer método, y se buscará el conjunto de estados que individualmente son más probables.

